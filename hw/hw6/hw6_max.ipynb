{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 6: Putting it all together \n",
    "### Associated lectures: All material till lecture 13 \n",
    "\n",
    "**Due date: Monday, November 15, 2021 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [Submission instructions](#si)\n",
    "- [Understanding the problem](#1)\n",
    "- [Data splitting](#2)\n",
    "- [EDA](#3)\n",
    "- (Optional) [Feature engineering](#4)\n",
    "- [Preprocessing and transformations](#5)\n",
    "- [Baseline model](#6)\n",
    "- [Linear models](#7)\n",
    "- [Different classifiers](#8)\n",
    "- (Optional) [Feature selection](#9)\n",
    "- [Hyperparameter optimization](#10)\n",
    "- [Interpretation and feature importances](#11)\n",
    "- [Results on the test set](#12)\n",
    "- (Optional) [Explaining predictions](#13)\n",
    "- [Summary of the results](#14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from scipy.stats import loguniform, randint\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    plot_confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330/blob/master/docs/homework_instructions.md). \n",
    "\n",
    "**You may work on this homework in a group and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 3. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "<hr>\n",
    "\n",
    "At this point we are at the end of supervised machine learning part of the course. So in this homework, you will be working on an open-ended mini-project, where you will put all the different things you have learned so far together to solve an interesting problem.\n",
    "\n",
    "A few notes and tips when you work on this mini-project: \n",
    "\n",
    "#### Tips\n",
    "\n",
    "1. This mini-project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "4. If you are having trouble running models on your laptop because of the size of the dataset, you can create your train/test split in such a way that you have less data in the train split. If you end up doing this, please write a note to the grader in the submission explaining why you are doing it.  \n",
    "\n",
    "#### Assessment\n",
    "\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "#### A final note\n",
    "\n",
    "Finally, this style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\" (2-8 hours???) is a good guideline for a typical submission. Of course if you're having fun you're welcome to spend as much time as you want! But, if so, try not to do it out of perfectionism or getting the best possible grade. Do it because you're learning and enjoying it. Students from the past cohorts have found such kind of labs useful and fun and I hope you enjoy it as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding the problem <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={points:4}\n",
    "\n",
    "In this mini project, you will be working on a classification problem of predicting whether a credit card client will default or not. \n",
    "For this problem, you will use [Default of Credit Card Clients Dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). In this data set, there are 30,000 examples and 24 features, and the goal is to estimate whether a person will default (fail to pay) their credit card bills; this column is labeled \"default.payment.next.month\" in the data. The rest of the columns can be used as features. You may take some ideas and compare your results with [the associated research paper](https://www.sciencedirect.com/science/article/pii/S0957417407006719), which is available through [the UBC library](https://www.library.ubc.ca/). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Spend some time understanding the problem and what each feature means. You can find this information in the documentation on [the dataset page on Kaggle](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). Write a few sentences on your initial thoughts on the problem and the dataset. \n",
    "2. Download the dataset and read it as a pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are predicting whether people are going to default on a credit card bill payment\n",
    "\n",
    "**Features**\n",
    "* `ID` is the index\n",
    "* `default.payment.next.month` is the target\n",
    "    * Default payment (1=yes, 0=no) \n",
    "\n",
    "**Categorical**\n",
    "* `MARRIAGE`: Marital status \n",
    "    * (1=married, 2=single, 3=others)\n",
    "* `EDUCATION`: (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown) We should be consolidating 5 and 6. \n",
    "* `PAY_X`: Repayment status \n",
    "    * (-2: No consumption; -1: Paid in full; 0: The use of revolving credit; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 9 = payment delay for nine months and above.)\n",
    "    * PAY_0: in September, 2005\n",
    "        * We should rename this to PAY_1 to be consistent with the BILL_AMT and PAY_AMT\n",
    "    * PAY_2: in August, 2005\n",
    "    * PAY_3: in July, 2005\n",
    "    * PAY_4: in June, 2005\n",
    "    * PAY_5: in May, 2005\n",
    "    * PAY_6: in April, 2005\n",
    "\n",
    "**Binary**\n",
    "* `SEX`: Gender (1=male, 2=female)\n",
    "    * we should leave this out, it is inappropriate to use sex to determine whether someone will default on their credit card payment.\n",
    "\n",
    "**Numerical**\n",
    "* `AGE`: Age in years\n",
    "* `LIMIT_BAL`: Amount of given credit in NT dollars (includes individual and family/supplementary credit)\n",
    "* `BILL_AMTX`: Amount of bill statement in NT dollar\n",
    "    * BILL_AMT1: in September, 2005\n",
    "    * BILL_AMT2: in August, 2005\n",
    "    * BILL_AMT3: in July, 2005\n",
    "    * BILL_AMT4: in June, 2005\n",
    "    * BILL_AMT5: in May, 2005\n",
    "    * BILL_AMT6: in April, 2005\n",
    "* `PAY_AMTX`: Amount of previous payment\n",
    "    * PAY_AMT1: in September, 2005\n",
    "    * PAY_AMT2: in August, 2005\n",
    "    * PAY_AMT3: in July, 2005\n",
    "    * PAY_AMT4: in June, 2005\n",
    "    * PAY_AMT5: in May, 2005\n",
    "    * PAY_AMT6: in April, 2005\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>DEFAULT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "ID                                                                         \n",
       "1     20000.0    2          2         1   24      2      2     -1     -1   \n",
       "2    120000.0    2          2         2   26     -1      2      0      0   \n",
       "3     90000.0    2          2         2   34      0      0      0      0   \n",
       "4     50000.0    2          2         1   37      0      0      0      0   \n",
       "5     50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "    PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "ID         ...                                                                  \n",
       "1      -2  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "2       0  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "3       0  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "4       0  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "5       0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "    PAY_AMT4  PAY_AMT5  PAY_AMT6  DEFAULT  \n",
       "ID                                         \n",
       "1        0.0       0.0       0.0        1  \n",
       "2     1000.0       0.0    2000.0        1  \n",
       "3     1000.0    1000.0    5000.0        0  \n",
       "4     1100.0    1069.0    1000.0        0  \n",
       "5     9000.0     689.0     679.0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"UCI_Credit_Card.csv\")\n",
    "df = df.set_index('ID')\n",
    "df = df.rename(columns={\"PAY_0\": \"PAY_1\"})\n",
    "df = df.rename(columns={\"default.payment.next.month\": \"DEFAULT\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data splitting <a name=\"2\"></a>\n",
    "<hr>\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train and test portions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=123)\n",
    "X_train = train_df.drop(columns=['DEFAULT'])\n",
    "X_test  = test_df.drop(columns=['DEFAULT'])\n",
    "y_train = train_df['DEFAULT']\n",
    "y_test = test_df['DEFAULT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA <a name=\"3\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. \n",
    "4. Pick appropriate metric/metrics for assessment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24000 entries, 19683 to 19967\n",
      "Data columns (total 23 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   LIMIT_BAL  24000 non-null  float64\n",
      " 1   SEX        24000 non-null  int64  \n",
      " 2   EDUCATION  24000 non-null  int64  \n",
      " 3   MARRIAGE   24000 non-null  int64  \n",
      " 4   AGE        24000 non-null  int64  \n",
      " 5   PAY_1      24000 non-null  int64  \n",
      " 6   PAY_2      24000 non-null  int64  \n",
      " 7   PAY_3      24000 non-null  int64  \n",
      " 8   PAY_4      24000 non-null  int64  \n",
      " 9   PAY_5      24000 non-null  int64  \n",
      " 10  PAY_6      24000 non-null  int64  \n",
      " 11  BILL_AMT1  24000 non-null  float64\n",
      " 12  BILL_AMT2  24000 non-null  float64\n",
      " 13  BILL_AMT3  24000 non-null  float64\n",
      " 14  BILL_AMT4  24000 non-null  float64\n",
      " 15  BILL_AMT5  24000 non-null  float64\n",
      " 16  BILL_AMT6  24000 non-null  float64\n",
      " 17  PAY_AMT1   24000 non-null  float64\n",
      " 18  PAY_AMT2   24000 non-null  float64\n",
      " 19  PAY_AMT3   24000 non-null  float64\n",
      " 20  PAY_AMT4   24000 non-null  float64\n",
      " 21  PAY_AMT5   24000 non-null  float64\n",
      " 22  PAY_AMT6   24000 non-null  float64\n",
      "dtypes: float64(13), int64(10)\n",
      "memory usage: 4.4 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>2.400000e+04</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>167893.486667</td>\n",
       "      <td>1.603125</td>\n",
       "      <td>1.851958</td>\n",
       "      <td>1.553375</td>\n",
       "      <td>35.488458</td>\n",
       "      <td>-0.017542</td>\n",
       "      <td>-0.135292</td>\n",
       "      <td>-0.170042</td>\n",
       "      <td>-0.224292</td>\n",
       "      <td>-0.265583</td>\n",
       "      <td>...</td>\n",
       "      <td>46955.185083</td>\n",
       "      <td>43389.105625</td>\n",
       "      <td>40297.970375</td>\n",
       "      <td>38708.777542</td>\n",
       "      <td>5656.319917</td>\n",
       "      <td>5.910454e+03</td>\n",
       "      <td>5280.658708</td>\n",
       "      <td>4763.854250</td>\n",
       "      <td>4805.837667</td>\n",
       "      <td>5277.577958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>130109.666875</td>\n",
       "      <td>0.489260</td>\n",
       "      <td>0.790560</td>\n",
       "      <td>0.521452</td>\n",
       "      <td>9.217424</td>\n",
       "      <td>1.125331</td>\n",
       "      <td>1.199812</td>\n",
       "      <td>1.201709</td>\n",
       "      <td>1.170630</td>\n",
       "      <td>1.136707</td>\n",
       "      <td>...</td>\n",
       "      <td>68841.868958</td>\n",
       "      <td>64572.844994</td>\n",
       "      <td>60878.153831</td>\n",
       "      <td>59355.284889</td>\n",
       "      <td>16757.718059</td>\n",
       "      <td>2.134743e+04</td>\n",
       "      <td>17973.951980</td>\n",
       "      <td>15162.056345</td>\n",
       "      <td>15251.828322</td>\n",
       "      <td>18222.046645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-157264.000000</td>\n",
       "      <td>-65167.000000</td>\n",
       "      <td>-61372.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2663.000000</td>\n",
       "      <td>2310.000000</td>\n",
       "      <td>1744.250000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>8.150000e+02</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>281.750000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>110.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20038.000000</td>\n",
       "      <td>19032.000000</td>\n",
       "      <td>18019.000000</td>\n",
       "      <td>16812.500000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.010000e+03</td>\n",
       "      <td>1801.500000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>59970.250000</td>\n",
       "      <td>54591.500000</td>\n",
       "      <td>50237.250000</td>\n",
       "      <td>49132.750000</td>\n",
       "      <td>5009.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4026.000000</td>\n",
       "      <td>4009.250000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>855086.000000</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.227082e+06</td>\n",
       "      <td>896040.000000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LIMIT_BAL           SEX     EDUCATION      MARRIAGE           AGE  \\\n",
       "count    24000.000000  24000.000000  24000.000000  24000.000000  24000.000000   \n",
       "mean    167893.486667      1.603125      1.851958      1.553375     35.488458   \n",
       "std     130109.666875      0.489260      0.790560      0.521452      9.217424   \n",
       "min      10000.000000      1.000000      0.000000      0.000000     21.000000   \n",
       "25%      50000.000000      1.000000      1.000000      1.000000     28.000000   \n",
       "50%     140000.000000      2.000000      2.000000      2.000000     34.000000   \n",
       "75%     240000.000000      2.000000      2.000000      2.000000     41.000000   \n",
       "max    1000000.000000      2.000000      6.000000      3.000000     79.000000   \n",
       "\n",
       "              PAY_1         PAY_2         PAY_3         PAY_4         PAY_5  \\\n",
       "count  24000.000000  24000.000000  24000.000000  24000.000000  24000.000000   \n",
       "mean      -0.017542     -0.135292     -0.170042     -0.224292     -0.265583   \n",
       "std        1.125331      1.199812      1.201709      1.170630      1.136707   \n",
       "min       -2.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       -1.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        8.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "       ...      BILL_AMT3      BILL_AMT4      BILL_AMT5      BILL_AMT6  \\\n",
       "count  ...   24000.000000   24000.000000   24000.000000   24000.000000   \n",
       "mean   ...   46955.185083   43389.105625   40297.970375   38708.777542   \n",
       "std    ...   68841.868958   64572.844994   60878.153831   59355.284889   \n",
       "min    ... -157264.000000  -65167.000000  -61372.000000 -339603.000000   \n",
       "25%    ...    2663.000000    2310.000000    1744.250000    1200.000000   \n",
       "50%    ...   20038.000000   19032.000000   18019.000000   16812.500000   \n",
       "75%    ...   59970.250000   54591.500000   50237.250000   49132.750000   \n",
       "max    ...  855086.000000  891586.000000  927171.000000  961664.000000   \n",
       "\n",
       "            PAY_AMT1      PAY_AMT2       PAY_AMT3       PAY_AMT4  \\\n",
       "count   24000.000000  2.400000e+04   24000.000000   24000.000000   \n",
       "mean     5656.319917  5.910454e+03    5280.658708    4763.854250   \n",
       "std     16757.718059  2.134743e+04   17973.951980   15162.056345   \n",
       "min         0.000000  0.000000e+00       0.000000       0.000000   \n",
       "25%       990.000000  8.150000e+02     390.000000     281.750000   \n",
       "50%      2100.000000  2.010000e+03    1801.500000    1500.000000   \n",
       "75%      5009.000000  5.000000e+03    4600.000000    4026.000000   \n",
       "max    873552.000000  1.227082e+06  896040.000000  621000.000000   \n",
       "\n",
       "            PAY_AMT5       PAY_AMT6  \n",
       "count   24000.000000   24000.000000  \n",
       "mean     4805.837667    5277.577958  \n",
       "std     15251.828322   18222.046645  \n",
       "min         0.000000       0.000000  \n",
       "25%       234.000000     110.750000  \n",
       "50%      1500.000000    1500.000000  \n",
       "75%      4009.250000    4000.000000  \n",
       "max    426529.000000  528666.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    12798\n",
       "1    10905\n",
       "3      260\n",
       "0       37\n",
       "Name: MARRIAGE, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.MARRIAGE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This summary statistic shows us the counts of values in the `MARRIAGE` feature. There are some with value 0, which we do not have in our legend (1=married, 2=single, 3=others). We should change all the 0s to 3s as they can safely be categorized as 'others'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    14030\n",
       "1    10585\n",
       "3     4917\n",
       "5      280\n",
       "4      123\n",
       "6       51\n",
       "0       14\n",
       "Name: EDUCATION, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.EDUCATION.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This summary statistic shows us the counts of values in the `EDUCATION` feature. There are some with value 0, which we do not have in our legend (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown). We should change all the 0s to 5s as they can safely be categorized as 'unknown', we can also change al the 6s to 5s since they are both for the same category ('unknown')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    11783\n",
       "-1     4604\n",
       " 1     2939\n",
       "-2     2183\n",
       " 2     2110\n",
       " 3      265\n",
       " 4       60\n",
       " 5       22\n",
       " 8       16\n",
       " 6        9\n",
       " 7        9\n",
       "Name: PAY_1, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.PAY_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train.AGE.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives us an idea of the age distribution of our dataset. Theres some imbalance but this is okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = y_train.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gives us an idea of the target value distribution in the dataset. We clearly have a large class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Appropriate metric for assessment is  validation/test accuracy since we are doing supervised machine learning. \n",
    "\n",
    "An appropriate metric would be recall since we have class imbalance and are trying to identify 'positive' examples. But we will use f1-score since it is more appropriate for hyper parameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = \"f1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 4. Feature engineering <a name=\"4\"></a>\n",
    "<hr>\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out feature engineering. In other words, extract new features relevant for the problem and work with your new feature set in the following exercises. You may have to go back and forth between feature engineering and preprocessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = ['SEX']\n",
    "numeric_features = [\n",
    "    'AGE',\n",
    "    'LIMIT_BAL',\n",
    "    'BILL_AMT1',\n",
    "    'BILL_AMT2',\n",
    "    'BILL_AMT3',\n",
    "    'BILL_AMT4',\n",
    "    'BILL_AMT5',\n",
    "    'BILL_AMT6',\n",
    "    'PAY_AMT1',\n",
    "    'PAY_AMT2',\n",
    "    'PAY_AMT3',\n",
    "    'PAY_AMT4',\n",
    "    'PAY_AMT5',\n",
    "    'PAY_AMT6',\n",
    "\n",
    "]\n",
    "categorical_features = [\n",
    "    'MARRIAGE', \n",
    "    'EDUCATION',\n",
    "    'PAY_1',\n",
    "    'PAY_2',\n",
    "    'PAY_3',\n",
    "    'PAY_4',\n",
    "    'PAY_5',\n",
    "    'PAY_6',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.MARRIAGE = df.MARRIAGE.replace([0], 3)\n",
    "df.EDUCATION = df.EDUCATION.replace([0, 6], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features will be dropped since they are not included\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),  # scaling on numeric features so they effect models evenly\n",
    "    (OneHotEncoder(sparse=False, handle_unknown = 'ignore'), categorical_features),  # OHE on categorical features so that we can use them in models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Baseline model <a name=\"6\"></a>\n",
    "<hr>\n",
    "\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on the training data: 0.778\n"
     ]
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train); # fit the classifier\n",
    "print(\"The accuracy of the model on the training data: %0.3f\" % (dummy_clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Linear models <a name=\"7\"></a>\n",
    "<hr>\n",
    "rubric={points:12}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try logistic regression as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter `C`. \n",
    "3. Report validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "pipe = make_pipeline(preprocessor, log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"logisticregression__C\": [0.1, 1.0, 10, 100, 1000],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=-1, return_train_score=True, scoring=scoring)\n",
    "grid_search.fit(X_train, y_train)\n",
    "results = pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.453560</td>\n",
       "      <td>0.197746</td>\n",
       "      <td>0.036240</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'logisticregression__C': 0.1}</td>\n",
       "      <td>0.461820</td>\n",
       "      <td>0.461059</td>\n",
       "      <td>0.444305</td>\n",
       "      <td>0.494204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465197</td>\n",
       "      <td>0.016166</td>\n",
       "      <td>4</td>\n",
       "      <td>0.469514</td>\n",
       "      <td>0.473538</td>\n",
       "      <td>0.473725</td>\n",
       "      <td>0.459913</td>\n",
       "      <td>0.470878</td>\n",
       "      <td>0.469514</td>\n",
       "      <td>0.005059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.372561</td>\n",
       "      <td>1.788064</td>\n",
       "      <td>0.056135</td>\n",
       "      <td>0.012184</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'logisticregression__C': 1.0}</td>\n",
       "      <td>0.459658</td>\n",
       "      <td>0.459527</td>\n",
       "      <td>0.447220</td>\n",
       "      <td>0.496652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464881</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>5</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.475985</td>\n",
       "      <td>0.463112</td>\n",
       "      <td>0.473019</td>\n",
       "      <td>0.471620</td>\n",
       "      <td>0.004430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.432112</td>\n",
       "      <td>3.810027</td>\n",
       "      <td>0.040808</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>10</td>\n",
       "      <td>{'logisticregression__C': 10}</td>\n",
       "      <td>0.458996</td>\n",
       "      <td>0.461443</td>\n",
       "      <td>0.445836</td>\n",
       "      <td>0.499392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465710</td>\n",
       "      <td>0.017893</td>\n",
       "      <td>1</td>\n",
       "      <td>0.472902</td>\n",
       "      <td>0.474754</td>\n",
       "      <td>0.476454</td>\n",
       "      <td>0.463543</td>\n",
       "      <td>0.473676</td>\n",
       "      <td>0.472266</td>\n",
       "      <td>0.004521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.705909</td>\n",
       "      <td>2.022958</td>\n",
       "      <td>0.029850</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>100</td>\n",
       "      <td>{'logisticregression__C': 100}</td>\n",
       "      <td>0.458996</td>\n",
       "      <td>0.461156</td>\n",
       "      <td>0.445141</td>\n",
       "      <td>0.499696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465574</td>\n",
       "      <td>0.018176</td>\n",
       "      <td>2</td>\n",
       "      <td>0.473285</td>\n",
       "      <td>0.474754</td>\n",
       "      <td>0.476528</td>\n",
       "      <td>0.463377</td>\n",
       "      <td>0.473749</td>\n",
       "      <td>0.472338</td>\n",
       "      <td>0.004617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.755532</td>\n",
       "      <td>2.538203</td>\n",
       "      <td>0.015967</td>\n",
       "      <td>0.005806</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'logisticregression__C': 1000}</td>\n",
       "      <td>0.458996</td>\n",
       "      <td>0.461156</td>\n",
       "      <td>0.445141</td>\n",
       "      <td>0.499696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465574</td>\n",
       "      <td>0.018176</td>\n",
       "      <td>2</td>\n",
       "      <td>0.473595</td>\n",
       "      <td>0.474754</td>\n",
       "      <td>0.476528</td>\n",
       "      <td>0.463615</td>\n",
       "      <td>0.473514</td>\n",
       "      <td>0.472401</td>\n",
       "      <td>0.004526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       3.453560      0.197746         0.036240        0.004449   \n",
       "1      10.372561      1.788064         0.056135        0.012184   \n",
       "2      16.432112      3.810027         0.040808        0.002916   \n",
       "3      25.705909      2.022958         0.029850        0.005274   \n",
       "4      21.755532      2.538203         0.015967        0.005806   \n",
       "\n",
       "  param_logisticregression__C                           params  \\\n",
       "0                         0.1   {'logisticregression__C': 0.1}   \n",
       "1                         1.0   {'logisticregression__C': 1.0}   \n",
       "2                          10    {'logisticregression__C': 10}   \n",
       "3                         100   {'logisticregression__C': 100}   \n",
       "4                        1000  {'logisticregression__C': 1000}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.461820           0.461059           0.444305           0.494204   \n",
       "1           0.459658           0.459527           0.447220           0.496652   \n",
       "2           0.458996           0.461443           0.445836           0.499392   \n",
       "3           0.458996           0.461156           0.445141           0.499696   \n",
       "4           0.458996           0.461156           0.445141           0.499696   \n",
       "\n",
       "   ...  mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0  ...         0.465197        0.016166                4            0.469514   \n",
       "1  ...         0.464881        0.016672                5            0.472300   \n",
       "2  ...         0.465710        0.017893                1            0.472902   \n",
       "3  ...         0.465574        0.018176                2            0.473285   \n",
       "4  ...         0.465574        0.018176                2            0.473595   \n",
       "\n",
       "   split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0            0.473538            0.473725            0.459913   \n",
       "1            0.473684            0.475985            0.463112   \n",
       "2            0.474754            0.476454            0.463543   \n",
       "3            0.474754            0.476528            0.463377   \n",
       "4            0.474754            0.476528            0.463615   \n",
       "\n",
       "   split4_train_score  mean_train_score  std_train_score  \n",
       "0            0.470878          0.469514         0.005059  \n",
       "1            0.473019          0.471620         0.004430  \n",
       "2            0.473676          0.472266         0.004521  \n",
       "3            0.473749          0.472338         0.004617  \n",
       "4            0.473514          0.472401         0.004526  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not great, we are correctly identifying a little more than a 3rd of the positive examples. The differences between the test scores and train scores are practically the same. We opt to use a C value of 10 as it gives us the best test score and does not appear to be overfitting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Different classifiers <a name=\"8\"></a>\n",
    "<hr>\n",
    "rubric={points:15}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try at least 3 other models aside from logistic regression. At least one of these models should be a tree-based ensemble model (e.g., lgbm, random forest, xgboost). \n",
    "2. Summarize your results. Can you beat logistic regression? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"SVM RBF\": SVC(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"LGBM\": LGBMClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "\n",
    "for name in models:\n",
    "    pipeline = make_pipeline(preprocessor, models[name])\n",
    "    out[name] = cross_validate(pipeline, X_train, y_train, scoring=scoring, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.284749</td>\n",
       "      <td>0.592014</td>\n",
       "      <td>0.179367</td>\n",
       "      <td>0.205950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.237137</td>\n",
       "      <td>0.589354</td>\n",
       "      <td>0.368517</td>\n",
       "      <td>0.375178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.901468</td>\n",
       "      <td>0.607427</td>\n",
       "      <td>0.093294</td>\n",
       "      <td>0.090253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.528211</td>\n",
       "      <td>0.585471</td>\n",
       "      <td>0.250856</td>\n",
       "      <td>0.250081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.740446</td>\n",
       "      <td>0.599626</td>\n",
       "      <td>0.407631</td>\n",
       "      <td>0.408421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  2.284749    0.592014    0.179367     0.205950\n",
       "1  2.237137    0.589354    0.368517     0.375178\n",
       "2  2.901468    0.607427    0.093294     0.090253\n",
       "3  2.528211    0.585471    0.250856     0.250081\n",
       "4  2.740446    0.599626    0.407631     0.408421"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(out['SVM RBF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.092749</td>\n",
       "      <td>0.094869</td>\n",
       "      <td>0.454002</td>\n",
       "      <td>0.997303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.090821</td>\n",
       "      <td>0.097519</td>\n",
       "      <td>0.464180</td>\n",
       "      <td>0.997536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.181124</td>\n",
       "      <td>0.090986</td>\n",
       "      <td>0.463592</td>\n",
       "      <td>0.998359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.052958</td>\n",
       "      <td>0.090372</td>\n",
       "      <td>0.504728</td>\n",
       "      <td>0.997536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.109062</td>\n",
       "      <td>0.096986</td>\n",
       "      <td>0.463488</td>\n",
       "      <td>0.997889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  3.092749    0.094869    0.454002     0.997303\n",
       "1  3.090821    0.097519    0.464180     0.997536\n",
       "2  3.181124    0.090986    0.463592     0.998359\n",
       "3  3.052958    0.090372    0.504728     0.997536\n",
       "4  3.109062    0.096986    0.463488     0.997889"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(out['Random Forest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.243408</td>\n",
       "      <td>0.013421</td>\n",
       "      <td>0.465835</td>\n",
       "      <td>0.573753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.252215</td>\n",
       "      <td>0.013025</td>\n",
       "      <td>0.475566</td>\n",
       "      <td>0.569139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.258166</td>\n",
       "      <td>0.014692</td>\n",
       "      <td>0.454657</td>\n",
       "      <td>0.563628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.379907</td>\n",
       "      <td>0.016548</td>\n",
       "      <td>0.514662</td>\n",
       "      <td>0.561101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.285583</td>\n",
       "      <td>0.014509</td>\n",
       "      <td>0.476481</td>\n",
       "      <td>0.564550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.243408    0.013421    0.465835     0.573753\n",
       "1  0.252215    0.013025    0.475566     0.569139\n",
       "2  0.258166    0.014692    0.454657     0.563628\n",
       "3  0.379907    0.016548    0.514662     0.561101\n",
       "4  0.285583    0.014509    0.476481     0.564550"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(out['LGBM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 9. Feature selection <a name=\"9\"></a>\n",
    "<hr>\n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to select relevant features. You may try `RFECV` or forward selection. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it in the next exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "rubric={points:15}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. You may pick one of the best performing models from the previous exercise and tune hyperparameters only for that model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svc = make_pipeline(preprocessor, SVC(max_iter=1000))\n",
    "svc_params = {\n",
    "    \"svc__C\": loguniform(1e-3, 1e3),\n",
    "    \"svc__gamma\": loguniform(1e-3, 1e3),\n",
    "}\n",
    "\n",
    "svc_search = RandomizedSearchCV(\n",
    "    pipe_svc, svc_params, cv=3, n_iter=10, n_jobs=-1, scoring=scoring, return_train_score=True\n",
    ")\n",
    "svc_search.fit(X_train, y_train)\n",
    "svc_results = pd.DataFrame(svc_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_svc__C</th>\n",
       "      <th>param_svc__gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.994055</td>\n",
       "      <td>0.514746</td>\n",
       "      <td>2.173012</td>\n",
       "      <td>0.077062</td>\n",
       "      <td>0.028911</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>{'svc__C': 0.02891137512106592, 'svc__gamma': ...</td>\n",
       "      <td>0.364030</td>\n",
       "      <td>0.364235</td>\n",
       "      <td>0.363767</td>\n",
       "      <td>0.364011</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>4</td>\n",
       "      <td>0.365012</td>\n",
       "      <td>0.363375</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.363955</td>\n",
       "      <td>0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.992519</td>\n",
       "      <td>0.485721</td>\n",
       "      <td>2.465714</td>\n",
       "      <td>0.066469</td>\n",
       "      <td>0.628969</td>\n",
       "      <td>708.561333</td>\n",
       "      <td>{'svc__C': 0.6289690360561194, 'svc__gamma': 7...</td>\n",
       "      <td>0.382014</td>\n",
       "      <td>0.382049</td>\n",
       "      <td>0.385200</td>\n",
       "      <td>0.383088</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>1</td>\n",
       "      <td>0.423259</td>\n",
       "      <td>0.421543</td>\n",
       "      <td>0.421451</td>\n",
       "      <td>0.422084</td>\n",
       "      <td>0.000832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.939749</td>\n",
       "      <td>0.485182</td>\n",
       "      <td>2.248941</td>\n",
       "      <td>0.125969</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>3.269717</td>\n",
       "      <td>{'svc__C': 0.004262517601290756, 'svc__gamma':...</td>\n",
       "      <td>0.064109</td>\n",
       "      <td>0.031612</td>\n",
       "      <td>0.028496</td>\n",
       "      <td>0.041406</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>9</td>\n",
       "      <td>0.282436</td>\n",
       "      <td>0.242277</td>\n",
       "      <td>0.240469</td>\n",
       "      <td>0.255061</td>\n",
       "      <td>0.019371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.521687</td>\n",
       "      <td>2.648756</td>\n",
       "      <td>2.386407</td>\n",
       "      <td>0.364984</td>\n",
       "      <td>201.156687</td>\n",
       "      <td>0.014697</td>\n",
       "      <td>{'svc__C': 201.15668715519854, 'svc__gamma': 0...</td>\n",
       "      <td>0.334202</td>\n",
       "      <td>0.350661</td>\n",
       "      <td>0.389710</td>\n",
       "      <td>0.358191</td>\n",
       "      <td>0.023278</td>\n",
       "      <td>7</td>\n",
       "      <td>0.347832</td>\n",
       "      <td>0.343699</td>\n",
       "      <td>0.391866</td>\n",
       "      <td>0.361132</td>\n",
       "      <td>0.021797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.731465</td>\n",
       "      <td>4.712436</td>\n",
       "      <td>3.096967</td>\n",
       "      <td>0.500420</td>\n",
       "      <td>0.843246</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>{'svc__C': 0.8432456302314724, 'svc__gamma': 0...</td>\n",
       "      <td>0.363111</td>\n",
       "      <td>0.364084</td>\n",
       "      <td>0.363972</td>\n",
       "      <td>0.363723</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>5</td>\n",
       "      <td>0.364442</td>\n",
       "      <td>0.363879</td>\n",
       "      <td>0.363440</td>\n",
       "      <td>0.363920</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.192004</td>\n",
       "      <td>2.941048</td>\n",
       "      <td>2.456753</td>\n",
       "      <td>0.061043</td>\n",
       "      <td>0.03917</td>\n",
       "      <td>0.040321</td>\n",
       "      <td>{'svc__C': 0.039169751888546114, 'svc__gamma':...</td>\n",
       "      <td>0.363382</td>\n",
       "      <td>0.383539</td>\n",
       "      <td>0.383953</td>\n",
       "      <td>0.376958</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>2</td>\n",
       "      <td>0.371646</td>\n",
       "      <td>0.383954</td>\n",
       "      <td>0.381227</td>\n",
       "      <td>0.378943</td>\n",
       "      <td>0.005278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.864309</td>\n",
       "      <td>2.015848</td>\n",
       "      <td>2.738982</td>\n",
       "      <td>0.314895</td>\n",
       "      <td>45.732119</td>\n",
       "      <td>299.781461</td>\n",
       "      <td>{'svc__C': 45.73211855982556, 'svc__gamma': 29...</td>\n",
       "      <td>0.017486</td>\n",
       "      <td>0.024959</td>\n",
       "      <td>0.023822</td>\n",
       "      <td>0.022089</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>10</td>\n",
       "      <td>0.440061</td>\n",
       "      <td>0.438543</td>\n",
       "      <td>0.442548</td>\n",
       "      <td>0.440384</td>\n",
       "      <td>0.001651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.261754</td>\n",
       "      <td>0.905688</td>\n",
       "      <td>2.347152</td>\n",
       "      <td>0.142474</td>\n",
       "      <td>3.355722</td>\n",
       "      <td>2.539434</td>\n",
       "      <td>{'svc__C': 3.355722258006147, 'svc__gamma': 2....</td>\n",
       "      <td>0.057060</td>\n",
       "      <td>0.068677</td>\n",
       "      <td>0.126722</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.030472</td>\n",
       "      <td>8</td>\n",
       "      <td>0.250409</td>\n",
       "      <td>0.259843</td>\n",
       "      <td>0.353554</td>\n",
       "      <td>0.287935</td>\n",
       "      <td>0.046559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.583197</td>\n",
       "      <td>3.075910</td>\n",
       "      <td>1.744114</td>\n",
       "      <td>0.288457</td>\n",
       "      <td>0.765241</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>{'svc__C': 0.7652410750430696, 'svc__gamma': 0...</td>\n",
       "      <td>0.362618</td>\n",
       "      <td>0.364182</td>\n",
       "      <td>0.364290</td>\n",
       "      <td>0.363697</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>6</td>\n",
       "      <td>0.364747</td>\n",
       "      <td>0.363561</td>\n",
       "      <td>0.363711</td>\n",
       "      <td>0.364007</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.201415</td>\n",
       "      <td>1.206530</td>\n",
       "      <td>1.403891</td>\n",
       "      <td>0.035796</td>\n",
       "      <td>4.093438</td>\n",
       "      <td>0.023084</td>\n",
       "      <td>{'svc__C': 4.093437506242384, 'svc__gamma': 0....</td>\n",
       "      <td>0.368492</td>\n",
       "      <td>0.376599</td>\n",
       "      <td>0.368428</td>\n",
       "      <td>0.371173</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>3</td>\n",
       "      <td>0.377581</td>\n",
       "      <td>0.372204</td>\n",
       "      <td>0.369589</td>\n",
       "      <td>0.373125</td>\n",
       "      <td>0.003327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_svc__C  \\\n",
       "0      27.994055      0.514746         2.173012        0.077062     0.028911   \n",
       "1      24.992519      0.485721         2.465714        0.066469     0.628969   \n",
       "2      28.939749      0.485182         2.248941        0.125969     0.004263   \n",
       "3      25.521687      2.648756         2.386407        0.364984   201.156687   \n",
       "4      15.731465      4.712436         3.096967        0.500420     0.843246   \n",
       "5      24.192004      2.941048         2.456753        0.061043      0.03917   \n",
       "6      25.864309      2.015848         2.738982        0.314895    45.732119   \n",
       "7      23.261754      0.905688         2.347152        0.142474     3.355722   \n",
       "8      15.583197      3.075910         1.744114        0.288457     0.765241   \n",
       "9      11.201415      1.206530         1.403891        0.035796     4.093438   \n",
       "\n",
       "  param_svc__gamma                                             params  \\\n",
       "0         0.001615  {'svc__C': 0.02891137512106592, 'svc__gamma': ...   \n",
       "1       708.561333  {'svc__C': 0.6289690360561194, 'svc__gamma': 7...   \n",
       "2         3.269717  {'svc__C': 0.004262517601290756, 'svc__gamma':...   \n",
       "3         0.014697  {'svc__C': 201.15668715519854, 'svc__gamma': 0...   \n",
       "4         0.001555  {'svc__C': 0.8432456302314724, 'svc__gamma': 0...   \n",
       "5         0.040321  {'svc__C': 0.039169751888546114, 'svc__gamma':...   \n",
       "6       299.781461  {'svc__C': 45.73211855982556, 'svc__gamma': 29...   \n",
       "7         2.539434  {'svc__C': 3.355722258006147, 'svc__gamma': 2....   \n",
       "8         0.002452  {'svc__C': 0.7652410750430696, 'svc__gamma': 0...   \n",
       "9         0.023084  {'svc__C': 4.093437506242384, 'svc__gamma': 0....   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0           0.364030           0.364235           0.363767         0.364011   \n",
       "1           0.382014           0.382049           0.385200         0.383088   \n",
       "2           0.064109           0.031612           0.028496         0.041406   \n",
       "3           0.334202           0.350661           0.389710         0.358191   \n",
       "4           0.363111           0.364084           0.363972         0.363723   \n",
       "5           0.363382           0.383539           0.383953         0.376958   \n",
       "6           0.017486           0.024959           0.023822         0.022089   \n",
       "7           0.057060           0.068677           0.126722         0.084153   \n",
       "8           0.362618           0.364182           0.364290         0.363697   \n",
       "9           0.368492           0.376599           0.368428         0.371173   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.000192                4            0.365012            0.363375   \n",
       "1        0.001494                1            0.423259            0.421543   \n",
       "2        0.016104                9            0.282436            0.242277   \n",
       "3        0.023278                7            0.347832            0.343699   \n",
       "4        0.000435                5            0.364442            0.363879   \n",
       "5        0.009601                2            0.371646            0.383954   \n",
       "6        0.003288               10            0.440061            0.438543   \n",
       "7        0.030472                8            0.250409            0.259843   \n",
       "8        0.000764                6            0.364747            0.363561   \n",
       "9        0.003837                3            0.377581            0.372204   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.363478          0.363955         0.000749  \n",
       "1            0.421451          0.422084         0.000832  \n",
       "2            0.240469          0.255061         0.019371  \n",
       "3            0.391866          0.361132         0.021797  \n",
       "4            0.363440          0.363920         0.000410  \n",
       "5            0.381227          0.378943         0.005278  \n",
       "6            0.442548          0.440384         0.001651  \n",
       "7            0.353554          0.287935         0.046559  \n",
       "8            0.363711          0.364007         0.000527  \n",
       "9            0.369589          0.373125         0.003327  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 0.6289690360561194, 'svc__gamma': 708.5613328404127}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Interpretation and feature importances <a name=\"1\"></a>\n",
    "<hr>\n",
    "rubric={points:15}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Use the methods we saw in class (e.g., `eli5`, `shap`) (or any other methods of your choice) to explain feature importances of one of the best performing models. Summarize your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svc_pipe = make_pipeline(preprocessor, SVC(C=0.63, gamma=700, max_iter=1000, probability=True))\n",
    "best_svc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from eli5 documentation\n",
    "perm = PermutationImportance(best_svc_pipe).fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0991\n",
       "                \n",
       "                    &plusmn; 0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x5\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.46%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0958\n",
       "                \n",
       "                    &plusmn; 0.0051\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x6\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0945\n",
       "                \n",
       "                    &plusmn; 0.0037\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x7\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0902\n",
       "                \n",
       "                    &plusmn; 0.0038\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x8\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0862\n",
       "                \n",
       "                    &plusmn; 0.0076\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x9\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0747\n",
       "                \n",
       "                    &plusmn; 0.0039\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x10\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.20%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0583\n",
       "                \n",
       "                    &plusmn; 0.0035\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x14\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0563\n",
       "                \n",
       "                    &plusmn; 0.0051\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x13\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0552\n",
       "                \n",
       "                    &plusmn; 0.0034\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x15\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0549\n",
       "                \n",
       "                    &plusmn; 0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x16\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0534\n",
       "                \n",
       "                    &plusmn; 0.0029\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x12\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0498\n",
       "                \n",
       "                    &plusmn; 0.0027\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x11\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0249\n",
       "                \n",
       "                    &plusmn; 0.0044\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0235\n",
       "                \n",
       "                    &plusmn; 0.0083\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x4\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.46%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0201\n",
       "                \n",
       "                    &plusmn; 0.0073\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x3\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0110\n",
       "                \n",
       "                    &plusmn; 0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x20\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.22%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0092\n",
       "                \n",
       "                    &plusmn; 0.0043\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x19\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.22%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0092\n",
       "                \n",
       "                    &plusmn; 0.0036\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x21\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0085\n",
       "                \n",
       "                    &plusmn; 0.0029\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x17\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.88%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0022\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                x22\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.88%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 3 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My model is very difficult to interpret. Everything has super low / similar importances and theyre all categorical variables that got renamed in OHE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "rubric={points:5}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data and report test scores. \n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-default       0.90      0.32      0.47     18668\n",
      "     default       0.27      0.88      0.41      5332\n",
      "\n",
      "    accuracy                           0.44     24000\n",
      "   macro avg       0.58      0.60      0.44     24000\n",
      "weighted avg       0.76      0.44      0.46     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_train, best_svc_pipe.predict(X_train), target_names=[\"non-default\", \"default\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-default       0.85      0.27      0.41      4696\n",
      "     default       0.24      0.83      0.37      1304\n",
      "\n",
      "    accuracy                           0.39      6000\n",
      "   macro avg       0.54      0.55      0.39      6000\n",
      "weighted avg       0.72      0.39      0.40      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_test, best_svc_pipe.predict(X_test), target_names=[\"non-default\", \"default\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are basically what we would expect from our CV experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) 13. Explaining predictions \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks**\n",
    "\n",
    "1. Take one or two test predictions and explain them with SHAP force plots.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Summary of results <a name=\"13\"></a>\n",
    "<hr>\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Report your final test score along with the metric you used. \n",
    "2. Write concluding remarks.\n",
    "3. Discuss other ideas that you did not try but could potentially improve the performance/interpretability . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final score was 0.83 recall for default, but the precision was really low so there were lots of false positives. To improve interpretability we should relabel the columns that OHE created to try and make some sense of them. To improve performance we should switch models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
