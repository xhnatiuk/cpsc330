Prof: vA-rA-dA (said quickly) or V or Ada

kvarada@cs.ubc.ca



For each lecture there will be some videos to watch. Not all content will be covered by the videos. Sometimes we will need to watch them before hand, other times we will watch them in class.



Types of machine learning - depends on problem we are trying to solve and the data available to us. 



Grouping is generally unsupervised. 



Build a ML model using `sklearn`: 

1. Create model instance
2. Create X & Y
3. `fit`
4. `score` to evaluate performance
5. `predict` on new examples

`sklearn` uses the word `fit` for training.



Decision trees need to 'learn' two things:

1. best feature to split on
2. threshold for the feature to split on at each node



We can control the specificity of the rules generated by setting a maximum depth for the tree. 

* A decision tree with only one split (depth = 1) is called a decision stump.

When we do not pass any arguments to the `DecisionTreeClassifier` all leaf nodes will be pure (only have 1 value). 



Parameters are what we learn during training.

Hyperparameters are the 'knobs' we can use to control the training/learning. 



Decision boundaries:  





should review learning objective to determine what I am supposed to understand after each lecture. 

# Thursday September 16th 2021

